House Prices - Advanced Regression Techniques
   
    * კონკურსის მიზანია მანქანური სწავლების მეთოდების გამოყენება სახლების ფასზე prediction-ის გასაკეთებლად.
    * პრობლემის გადასაჭრელად გამოვიყენე მონაცემების გასუფთავების სხვადასხვა მეთოდები და LinearRegression, DecissionTree, Ridge მოდელები.

რეპოზიტორიის სტრუქტურა

    * model_experiment-0.ipynb : ამ ფაილში არის მონაცემების დამუშავების კოდი და ტრენინგისთვის გამოყენებულია ჯერ LinearRegression, ხოლო შემდგომ Ridge მოდელი. 
    
    * model_experiment-1.ipynb : ამ ფაილში მონაცემთა დასამუშავებლად გამოყენებულია იგივე მეთოდები, ხოლო მოდელი რომლის ოპტიმიზაციასაც ვცდილობ არის DecissionTree, რადგან ამ მოდელს მრავალი სხვადასხვა პარამეტრი გადაეცემა და ამასთანავე ტესტის რაოდენობაც შეზღუდულია გამოვიყენე K_Fold cross validation მიდგომა GridSearchCV-სთან ერთად.
    
    * model_inference : ამ ფაილში მოთხოვნის შესაბამისად ხდება ტესტ სეტ-ზე პროგნოზი, mlflow-დან ხდება, ჩემი აზრით, საუკეთესო მოდელის ჩამოტვირთვა და მისი მეშვეობით კეთდება პროგნოზი.
    
    * submission.csv : ფაილი, რომელიც კონკურსზე ავტვირთე.

Feature Engineering, Feature Selection

    * პირველ ექსპერიმენტში კატეგორიული ცვლადების და Nan მნიშვნელობების მქონე სვეტები უბრალოდ გადავყარე, რაც ცხადია არც ისე კარგი მიდგომაა(ფაილში ეს კოდი აღარ არის). ამის ნაცვლად უკეთესი შედეგი მომცა რიცხვითი Nan მნიშვნელობების საშუალოთი, ხოლო კატეგორიულის მოდით შევსებამ.
    * კატეგორიული ცვლადების რიცხვითშო გადასაყვანად გამოვიყენე OrdinalEncoder, რაც პრინციპში არც ისეთი კარგი მიდგომაა და ამ მხრივ ოპტიმიზაცია ნამდვილად შესაძლებელია.
    * ასევე ის სვეტები, რომლებსაც ძალიან ბევრი Nan მნიშვნელობა ჰქონდა(50% ზე მეტი) გადავყარე, რადგან დიდი ალბათობით ასეთი სვეტები ნაკლებად შეიცავენ გამოსადეგ ინფორმაციას (შესაძლოა 80% უკეთესი ვარიანტი ყოფილიყო ამ მხრივ, მაგრამ საბოლოო ჯამში სულ 5 სვეტი ამოვარდა)

Training

    * სამი მოდელი გავტესტე ამ დავალების ფარგლებში. ყველაზე კარგი შედეგი მომცა Ridge მოდელმა. DecissionTree-ის გატესტვისას მრავალი სხვადასხვა პარამეტრი მოვსინჯე და K_Fold-ც გამოვიყენე, თუმცა, ჩემი აზრით, ამ ამოცანის გადასაწყვეტად არც ისე კარგი მოდელია. (RMSE ზედმეტად დიდი იყო სხვა მოდელებთან შედარებით.)
    * პარამეტრების ოპტიმიზაციისთვის model_experiment-1.ipynb ფაილში გამოვიყენე GridSearchCV რათა რამდენიმე სხვადასხვა ვარიანტი მეცადა და მათგან საუკეთესო ამერჩია.
    * საბოლოოდ შევარჩიე Ridge მოდელი, რადგან მან მომცა სტაბილურად კარგი შედეგები.

MLflow Tracking

    * MLflow ექსპერიმენტების ბმული: 
       https://dagshub.com/Givi-Modebadze/my-first-repo.mlflow/#/experiments/2?searchFilter=&orderByKey=attributes.start_time&orderByAsc=false&startTime=ALL&lifecycleFilter=Active&modelVersionFilter=All+Runs&datasetsFilter=W10%3D

       https://dagshub.com/Givi-Modebadze/my-first-repo.mlflow/#/experiments/3?searchFilter=&orderByKey=attributes.start_time&orderByAsc=false&startTime=ALL&lifecycleFilter=Active&modelVersionFilter=All+Runs&datasetsFilter=W10%3D
    * ჩაწერილი მეტრიკების აღწერა:
       ჩევიწერე r2, rmse და mae პარამეტრები თითოეული ექსპერიმენტისთვის როგორც ტესტ სეტზე ასევე ტრეის სეტზე.

    * საუკეთესო მოდელის შედეგები:
      train_r2: 0.8001737853313143
      train_rmse: 34523.52132373247
      train_mae: 19690.594356155318
      test_r2: 0.8308806976767621
      test_rmse: 36016.66581946661
      test_mae: 20925.446425622315
      kaggle_ზე submission: 0.18185

      ერთი შეხედვით უკეთესი შედეგი ჰქონდა rmse-ზე LinearRegression მოდელს. თუმცა,  სავარაუდოდ, overfitting მოხდა სატესტო მონაცემებზე. DecissionTree-შიც შეიქმნებოდა ეს პრობლემა, რომ არ გამომეყენებინა K_Fold და სხვადასხვა ჰიპერპარამეტრები არ შემემოწმებინა.


